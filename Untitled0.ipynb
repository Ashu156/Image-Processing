{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjoKjQgrbDcrPvUprAcFiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashu156/Image-Processing/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C8yqFEVhpVQ"
      },
      "outputs": [],
      "source": [
        "!pip install fastcore opencv-python-headless==4.5.4.60\n",
        "!pip install git+https://github.com/MouseLand/cellpose.git@316927eff7ad2201391957909a2114c68baee309"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbDoXA3PKNAm"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import tifffile\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "from pathlib import Path\n",
        "from cellpose import models, dynamics\n",
        "from fastcore.foundation import L\n",
        "from skimage.color import label2rgb\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNwYiX9RmiMX"
      },
      "source": [
        "# Connect to drive\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "except:\n",
        "  print('Google Drive is not available.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8LFII70JHOl"
      },
      "source": [
        "DATASET = 'cFOS_in_HC'\n",
        "SEED = 0 # We used seeds [0,1,2] in our experiemnts\n",
        "OUTPUT_PATH = Path(\"/content/predictions\") # Save predictions here\n",
        "MODEL_PATH = Path(\"/content/models\") # Save models here\n",
        "PREPROC_PATH = Path(\"/content/data\")\n",
        "DATA_PATH = Path('/gdrive/MyDrive/deepflash2-paper/data')\n",
        "TRAINED_MODEL_PATH= Path('/gdrive/MyDrive/benchmark_models/cellpose/')\n",
        "path = DATA_PATH/DATASET\n",
        "\n",
        "pretrained_dict = {\n",
        "    'PV_in_HC':'cyto', \n",
        "    'cFOS_in_HC':'cyto2',\n",
        "    'mScarlet_in_PAG':'cyto2',\n",
        "    'YFP_in_CTX':'cyto',\n",
        "    'GFAP_in_HC':'cyto2'\n",
        "}\n",
        "\n",
        "diam_dict = {\n",
        "    'PV_in_HC':24, \n",
        "    'cFOS_in_HC':15, \n",
        "    'mScarlet_in_PAG':55, \n",
        "    'YFP_in_CTX':50,\n",
        "    'GFAP_in_HC':17\n",
        "}\n",
        "\n",
        "mean_diam_dict = {\n",
        "    'PV_in_HC':30, \n",
        "    'cFOS_in_HC':17, \n",
        "    'mScarlet_in_PAG':17,\n",
        "    'YFP_in_CTX':30,\n",
        "    'GFAP_in_HC':17,\n",
        "}\n",
        "\n",
        "# cellpose settings\n",
        "channels=[0,0]\n",
        "use_GPU = True\n",
        "device = models.assign_device(True, use_GPU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ugKa2eQhq9"
      },
      "source": [
        "train_image_path = path/'train'/'images'\n",
        "train_masks_path = path/'train'/'masks_STAPLE'\n",
        "\n",
        "train_preproc_path = PREPROC_PATH/DATASET/f'train'\n",
        "train_preproc_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "train_images = [x for x in train_image_path.iterdir() if not x.name.startswith('.')]\n",
        "label_fn = lambda x: train_masks_path/f'{x.name[:-4]}_mask.png'\n",
        "\n",
        "for f in train_images:\n",
        "\n",
        "    # images\n",
        "    img = imageio.imread(f)\n",
        "    shape_orig = img.shape\n",
        "    min_shape = min(img.shape)\n",
        "    img = img[:min_shape,:min_shape]\n",
        "    print(f, shape_orig, img.shape)\n",
        "    tifffile.imwrite(train_preproc_path/f'{f.stem}_img.tif', img, compress=6)\n",
        "\n",
        "    # masks\n",
        "    msk = imageio.imread(label_fn(f))\n",
        "    # These labels can be noisy due to the ground truth estimation procedure (STAPLE)\n",
        "    _, label_msk = cv2.connectedComponents(msk.astype('uint8'), connectivity=4)\n",
        "    tifffile.imwrite(train_preproc_path/f'{f.stem}_masks.tif', label_msk, compress=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj5_-0EaHeU0"
      },
      "source": [
        "test_image_path = path/'test'/'images'\n",
        "test_files = [x for x in test_image_path.iterdir() if not x.name.startswith('.')]\n",
        "test_images = list(tifffile.imread(test_files))\n",
        "    \n",
        "for model_type in ['cellpose_ensemble', 'cellpose_single', 'cellpose']:\n",
        "\n",
        "    if model_type=='cellpose':\n",
        "        print(model_type)\n",
        "        model_type2=pretrained_dict[DATASET]\n",
        "        model = models.Cellpose(gpu=use_GPU, model_type=model_type2)\n",
        "\n",
        "        masks, flows, styles, diams = model.eval(test_images, \n",
        "                                          diameter=diam_dict[DATASET], \n",
        "                                          channels=channels\n",
        "                                        )\n",
        "\n",
        "    else:\n",
        "        print('Using fine tuned model')\n",
        "        pretrained_models = [x.as_posix() for x in (TRAINED_MODEL_PATH/f'{SEED+1}'/DATASET/'models').iterdir() \n",
        "                             if not x.name.endswith('_size.npy') and not x.name.startswith('.')]\n",
        "        if model_type=='cellpose_single': pretrained_models = pretrained_models[:1]\n",
        "        print(pretrained_models)\n",
        "        model = models.CellposeModel(gpu=use_GPU, \n",
        "                                     pretrained_model=pretrained_models,\n",
        "                                     diam_mean=mean_diam_dict[DATASET], \n",
        "                                    )\n",
        "        \n",
        "        masks, flows, styles = model.eval(test_images, \n",
        "                                          diameter=diam_dict[DATASET], \n",
        "                                          channels=channels\n",
        "                                        )\n",
        "\n",
        "\n",
        "    \n",
        "    prediction_path = OUTPUT_PATH/DATASET/model_type\n",
        "    for i, f in enumerate(test_files):\n",
        "        print(f.name)\n",
        "        idx = f.stem\n",
        "        label_msk = masks[i]\n",
        "        # Save semantic segmentation prediction\n",
        "        masks_path = prediction_path/'masks'\n",
        "        masks_path.mkdir(parents=True, exist_ok=True)\n",
        "        imageio.imwrite(masks_path/f'{idx}.png', ((label_msk>0)*255).astype('uint8'))\n",
        "\n",
        "        # Save instance segmentation prediction\n",
        "        instance_masks_path = prediction_path/'instance_masks'\n",
        "        instance_masks_path.mkdir(exist_ok=True)\n",
        "        tifffile.imwrite(instance_masks_path/f'{idx}.tif', label_msk.astype('int16'), compress=6)\n",
        "\n",
        "        # Plot\n",
        "        fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
        "        axs[0].imshow(label_msk>0)\n",
        "        axs[0].set_title(f'Semantic segmentation {idx}')\n",
        "        axs[1].imshow(label2rgb(label_msk, bg_label=0))\n",
        "        axs[1].set_title(f'Instance segmentation {idx}')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}